{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIM-Harvard/alpha_aime/blob/main/aime/nnunet_pancreas/notebooks/idc_nnunet_pancreas_mwe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmb_HiJv7Sit"
      },
      "source": [
        "# **nnU-Net for Pancreas and Pancreatic Cancer Segmentation**\n",
        "\n",
        "Minimal Working Example for cloud-based analysis of data using the nnU-Net pancreas and pancreatic cancer segmentation model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ignore the comments - need to be updated!\n",
        "\n",
        "Also, the test repo can be found at: [https://github.com/AIM-Harvard/alpha_aime](https://github.com/AIM-Harvard/alpha_aime)"
      ],
      "metadata": {
        "id": "VzWMeEhmzbf2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZnoRi9Y7nEB"
      },
      "source": [
        "## **Environment Setup**\n",
        "\n",
        "This demo notebook is intended to be run using a GPU.\n",
        "\n",
        "To access a free GPU on Colab:\n",
        "`Edit > Notebooks Settings`.\n",
        "\n",
        "From the dropdown menu under `Hardware accelerator`, select `GPU`. Let's check the Colab instance is indeed equipped with a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "non5qVLIcG4M",
        "outputId": "da415523-c8c5-45a5-a29c-e505c9b05507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep  9 15:14:40 2022\n",
            "\n",
            "Current directory : /content\n",
            "Hostname          : 7e43c1fd07cf\n",
            "Username          : root\n",
            "Python version    : 3.7.13 (default, Apr 24 2022, 01:04:09) \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import yaml\n",
        "\n",
        "import time\n",
        "import tqdm\n",
        "\n",
        "\n",
        "# useful information\n",
        "curr_dir = !pwd\n",
        "curr_droid = !hostname\n",
        "curr_pilot = !whoami\n",
        "\n",
        "print(time.asctime(time.localtime()))\n",
        "\n",
        "print(\"\\nCurrent directory :\", curr_dir[-1])\n",
        "print(\"Hostname          :\", curr_droid[-1])\n",
        "print(\"Username          :\", curr_pilot[-1])\n",
        "\n",
        "print(\"Python version    :\", sys.version.split('\\n')[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The authentication to Google is necessary to run BigQuery queries.\n",
        "\n",
        "Every operation throughout the whole notebook (BigQuery, fetching data from the IDC buckets) is completely free. The only thing that is needed in order to run the notebook is the set-up of a Google Cloud project. In order for the notebook to work as intended, you will need to specify the name of the project in the cell after the authentication one."
      ],
      "metadata": {
        "id": "0PKq2z2jkVJz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DMUqTOVF5WP"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y43S1F35h8m"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "from google.cloud import bigquery as bq\n",
        "\n",
        "# INSERT THE NAME OF YOUR PROJECT HERE!\n",
        "#project_name = \"idc-sandbox-000\"\n",
        "project_name = \"sage-buttress-323909\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT7coYaGfd4t"
      },
      "source": [
        "Throughout this Colab notebook, for image pre-processing we will use [Plastimatch](https://plastimatch.org), a reliable and open source software for image computation. We will be running Plastimatch using the simple [PyPlastimatch](https://github.com/AIM-Harvard/pyplastimatch/tree/main/pyplastimatch) python wrapper. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NLhlFqyEgBf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt install plastimatch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ILwxgbcfcpr",
        "outputId": "26cce1e6-9d08-4eb5-c061-490072c1e610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plastimatch version 1.7.0\n"
          ]
        }
      ],
      "source": [
        "# check plastimatch was correctly installed\n",
        "!plastimatch --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use subversion to clone only a few subdirectories of a repository (this is still not simple to do using the git CLI)."
      ],
      "metadata": {
        "id": "IAbQc9NEC8vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!apt install subversion"
      ],
      "metadata": {
        "id": "9onAGEa5C4Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check plastimatch was correctly installed\n",
        "!svn --version | head -n 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2aqVUteC4bc",
        "outputId": "fa49cae2-f9dc-45a0-b231-f9fec3d4a096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svn, version 1.9.7 (r1800392)\n",
            "   compiled May 21 2022, 07:24:25 on x86_64-pc-linux-gnu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone only the subfolders of `ImagingDataCommons/ai_medima_misc` we need to run this notebook."
      ],
      "metadata": {
        "id": "iI4iYG6nDT73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1GgmTW5Mq6A",
        "outputId": "17019e4e-a683-4630-c5f5-f356e080aa5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A    src/README.md\n",
            "A    src/utils\n",
            "A    src/utils/eval.py\n",
            "A    src/utils/gcs.py\n",
            "A    src/utils/postprocessing.py\n",
            "A    src/utils/preprocessing.py\n",
            "A    src/utils/processing.py\n",
            "Checked out revision 51.\n",
            "A    data/dicomseg_base_metadata.json\n",
            "A    data/dicomseg_metadata.json\n",
            "A    data/features_SR.json\n",
            "A    data/nnunet_segments_code_mapping.csv\n",
            "A    data/nnunet_shape_features_code_mapping.csv\n",
            "Checked out revision 51.\n"
          ]
        }
      ],
      "source": [
        "!svn checkout https://github.com/ImagingDataCommons/ai_medima_misc/trunk/nnunet/src\n",
        "!svn checkout https://github.com/ImagingDataCommons/ai_medima_misc/trunk/nnunet/data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Furthermore, to organise the DICOM data in a more common (and human-understandable) fashion after downloading those from the buckets, we will make use of [DICOMSort](https://github.com/pieper/dicomsort). \n",
        "\n",
        "DICOMSort is an open source tool for custom sorting and renaming of dicom files based on their specific DICOM tags. In our case, we will exploit DICOMSort to organise the DICOM data by `PatientID` and `Modality` - so that the final directory will look like the following:\n",
        "\n",
        "```\n",
        "data/raw/nsclc-radiomics/dicom/$PatientID\n",
        " └─── CT\n",
        "       ├─── $SOPInstanceUID_slice0.dcm\n",
        "       ├─── $SOPInstanceUID_slice1.dcm\n",
        "       ├───  ...\n",
        "       │\n",
        "      RTSTRUCT \n",
        "       ├─── $SOPInstanceUID_RTSTRUCT.dcm\n",
        "      SEG\n",
        "       └─── $SOPInstanceUID_RTSEG.dcm\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "Pcj1hYK7lzmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p src\n",
        "\n",
        "!git clone https://github.com/pieper/dicomsort src/dicomsort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py53FxrlD9eK",
        "outputId": "5ec5b1ee-6c87-4893-d998-caa1d317a5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'src/dicomsort'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 130 (delta 0), reused 1 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (130/130), 44.12 KiB | 2.59 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ztrKrzSm1WT"
      },
      "source": [
        "Finally, we will use DCMQI for converting the resulting segmentation into standard DICOM SEG objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYf72nA8m0wh",
        "outputId": "85c47c4c-66e8-494a-f758-a7a3821854d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-09 15:15:22--  https://github.com/QIICR/dcmqi/releases/download/v1.2.4/dcmqi-1.2.4-linux.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/50675718/04f07880-81ee-11eb-92ec-30c7426dae5d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220909%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220909T151522Z&X-Amz-Expires=300&X-Amz-Signature=c33e8c03197777c9ff4023e288151207a2a8b6b6b49fa2dc81698c1a787593b1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50675718&response-content-disposition=attachment%3B%20filename%3Ddcmqi-1.2.4-linux.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-09 15:15:22--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/50675718/04f07880-81ee-11eb-92ec-30c7426dae5d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220909%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220909T151522Z&X-Amz-Expires=300&X-Amz-Signature=c33e8c03197777c9ff4023e288151207a2a8b6b6b49fa2dc81698c1a787593b1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50675718&response-content-disposition=attachment%3B%20filename%3Ddcmqi-1.2.4-linux.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21561544 (21M) [application/octet-stream]\n",
            "Saving to: ‘/content/dcmqi-1.2.4-linux.tar.gz’\n",
            "\n",
            "/content/dcmqi-1.2. 100%[===================>]  20.56M  29.4MB/s    in 0.7s    \n",
            "\n",
            "2022-09-09 15:15:23 (29.4 MB/s) - ‘/content/dcmqi-1.2.4-linux.tar.gz’ saved [21561544/21561544]\n",
            "\n",
            "dcmqi-1.2.4-linux/share/\n",
            "dcmqi-1.2.4-linux/share/doc/\n",
            "dcmqi-1.2.4-linux/share/doc/ITK-4.10/\n",
            "dcmqi-1.2.4-linux/share/doc/ITK-4.10/itksys/\n",
            "dcmqi-1.2.4-linux/share/doc/ITK-4.10/itksys/Copyright.txt\n",
            "dcmqi-1.2.4-linux/bin/\n",
            "dcmqi-1.2.4-linux/bin/itkimage2segimage.xml\n",
            "dcmqi-1.2.4-linux/bin/itkimage2paramap\n",
            "dcmqi-1.2.4-linux/bin/segimage2itkimage.xml\n",
            "dcmqi-1.2.4-linux/bin/tid1500reader.xml\n",
            "dcmqi-1.2.4-linux/bin/paramap2itkimage\n",
            "dcmqi-1.2.4-linux/bin/segimage2itkimage\n",
            "dcmqi-1.2.4-linux/bin/tid1500writer\n",
            "dcmqi-1.2.4-linux/bin/paramap2itkimage.xml\n",
            "dcmqi-1.2.4-linux/bin/itkimage2segimage\n",
            "dcmqi-1.2.4-linux/bin/tid1500writer.xml\n",
            "dcmqi-1.2.4-linux/bin/tid1500reader\n",
            "dcmqi-1.2.4-linux/bin/itkimage2paramap.xml\n"
          ]
        }
      ],
      "source": [
        "dcmqi_release_url = \"https://github.com/QIICR/dcmqi/releases/download/v1.2.4/dcmqi-1.2.4-linux.tar.gz\"\n",
        "dcmqi_download_path = \"/content/dcmqi-1.2.4-linux.tar.gz\"\n",
        "dcmqi_path = \"/content/dcmqi-1.2.4-linux\"\n",
        "\n",
        "!wget -O $dcmqi_download_path $dcmqi_release_url\n",
        "\n",
        "!tar -xvf $dcmqi_download_path\n",
        "\n",
        "!mv $dcmqi_path/bin/* /bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JBJmF7rmz1S"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CthT1kRuywEh"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyplastimatch nnunet ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import random\n",
        "\n",
        "import json\n",
        "import pprint\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import SimpleITK as sitk\n",
        "import pyplastimatch as pypla\n",
        "\n",
        "print(\"Python version               : \", sys.version.split('\\n')[0])\n",
        "print(\"Numpy version                : \", np.__version__)\n",
        "\n",
        "# ----------------------------------------\n",
        "\n",
        "#everything that has to do with plotting goes here below\n",
        "import matplotlib\n",
        "matplotlib.use(\"agg\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = \"png\"\n",
        "\n",
        "import ipywidgets as ipyw\n",
        "\n",
        "## ----------------------------------------\n",
        "\n",
        "# create new colormap appending the alpha channel to the selected one\n",
        "# (so that we don't get a \\\"color overlay\\\" when plotting the segmask superimposed to the CT)\n",
        "cmap = plt.cm.Reds\n",
        "my_reds = cmap(np.arange(cmap.N))\n",
        "my_reds[:, -1] = np.linspace(0, 1, cmap.N)\n",
        "my_reds = ListedColormap(my_reds)\n",
        "\n",
        "cmap = plt.cm.Greens\n",
        "my_greens = cmap(np.arange(cmap.N))\n",
        "my_greens[:, -1] = np.linspace(0, 1, cmap.N)\n",
        "my_greens = ListedColormap(my_greens)\n",
        "\n",
        "cmap = plt.cm.Blues\n",
        "my_blues = cmap(np.arange(cmap.N))\n",
        "my_blues[:, -1] = np.linspace(0, 1, cmap.N)\n",
        "my_blues = ListedColormap(my_blues)\n",
        "\n",
        "cmap = plt.cm.spring\n",
        "my_spring = cmap(np.arange(cmap.N))\n",
        "my_spring[:, -1] = np.linspace(0, 1, cmap.N)\n",
        "my_spring = ListedColormap(my_spring)\n",
        "## ----------------------------------------\n",
        "\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3euRfHl7pe2u",
        "outputId": "c2c1fda1-3aa3-456b-dbcc-b6f393738481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version               :  3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "Numpy version                :  1.21.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provided everything was set up correctly, we can run the BigQuery query and get all the information we need to download the testing data from the IDC platform.\n",
        "\n",
        "For this specific use case, we are going to be working with the NSCLC-Radiomics collection (Chest CT scans of lung cancer patients, with manual delineation of various organs at risk)."
      ],
      "metadata": {
        "id": "aZOtlGtcmOq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery --project=$project_name cohort_df\n",
        "\n",
        "SELECT\n",
        "  dicom_pivot_v10.PatientID,\n",
        "  dicom_pivot_v10.collection_id,\n",
        "  dicom_pivot_v10.source_DOI,\n",
        "  dicom_pivot_v10.StudyInstanceUID,\n",
        "  dicom_pivot_v10.SeriesInstanceUID,\n",
        "  dicom_pivot_v10.SOPInstanceUID,\n",
        "  dicom_pivot_v10.gcs_url\n",
        "FROM\n",
        "  `bigquery-public-data.idc_v10.dicom_pivot_v10` dicom_pivot_v10\n",
        "WHERE\n",
        "  StudyInstanceUID IN (\n",
        "    SELECT\n",
        "      StudyInstanceUID\n",
        "    FROM\n",
        "      `bigquery-public-data.idc_v10.dicom_pivot_v10` dicom_pivot_v10\n",
        "    WHERE\n",
        "      (\n",
        "        LOWER(dicom_pivot_v10.collection_id) LIKE LOWER('pancreas_ct')\n",
        "      )\n",
        "    GROUP BY\n",
        "      StudyInstanceUID\n",
        "  )\n",
        "GROUP BY\n",
        "  dicom_pivot_v10.PatientID,\n",
        "  dicom_pivot_v10.collection_id,\n",
        "  dicom_pivot_v10.source_DOI,\n",
        "  dicom_pivot_v10.StudyInstanceUID,\n",
        "  dicom_pivot_v10.SeriesInstanceUID,\n",
        "  dicom_pivot_v10.SOPInstanceUID,\n",
        "  dicom_pivot_v10.gcs_url\n",
        "ORDER BY\n",
        "  dicom_pivot_v10.PatientID ASC,\n",
        "  dicom_pivot_v10.collection_id ASC,\n",
        "  dicom_pivot_v10.source_DOI ASC,\n",
        "  dicom_pivot_v10.StudyInstanceUID ASC,\n",
        "  dicom_pivot_v10.SeriesInstanceUID ASC,\n",
        "  dicom_pivot_v10.SOPInstanceUID ASC,\n",
        "  dicom_pivot_v10.gcs_url ASC"
      ],
      "metadata": {
        "id": "_8hRj0E5FW0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this works as intended only if the BQ query parses data from a single dataset\n",
        "# if not, feel free to set the name manually!\n",
        "dataset_name = cohort_df[\"collection_id\"].values[0]"
      ],
      "metadata": {
        "id": "oZApCCVLkZyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNutD-SRN52T"
      },
      "outputs": [],
      "source": [
        "# create the directory tree\n",
        "!mkdir -p data models output\n",
        "\n",
        "!mkdir -p data/raw \n",
        "!mkdir -p data/raw/tmp data/raw/$dataset_name\n",
        "!mkdir -p data/raw/$dataset_name/dicom\n",
        "\n",
        "!mkdir -p data/processed\n",
        "!mkdir -p data/processed/$dataset_name\n",
        "!mkdir -p data/processed/$dataset_name/nrrd\n",
        "!mkdir -p data/processed/$dataset_name/nii\n",
        "!mkdir -p data/processed/$dataset_name/dicomseg\n",
        "\n",
        "!mkdir -p data/model_input/\n",
        "!mkdir -p data/nnunet_output/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7y3FRa7rbyr"
      },
      "source": [
        "Download the segmentation model(s) from Zenodo. This can either be very fast (2m or even less) or very slow (up to 10m), probably depending on the traffic on the Zenodo's end and other factors.\n",
        "\n",
        "If the download is taking a long time, consider interrupting the celle execution and running the cell again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ79vTL5ef11",
        "outputId": "7c326b8f-3010-4124-c1d9-82f3a3d21dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-09 15:16:01--  https://zenodo.org/record/4003545/files/Task007_Pancreas.zip?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5002701016 (4.7G) [application/octet-stream]\n",
            "Saving to: ‘/content/models/Task055_SegTHOR.zip’\n",
            "\n",
            "/content/models/Tas 100%[===================>]   4.66G  22.6MB/s    in 3m 20s  \n",
            "\n",
            "2022-09-09 15:19:23 (23.8 MB/s) - ‘/content/models/Task055_SegTHOR.zip’ saved [5002701016/5002701016]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "seg_model_url = \"https://zenodo.org/record/4003545/files/Task007_Pancreas.zip?download=1\"\n",
        "model_download_path = \"/content/models/Task055_SegTHOR.zip\"\n",
        "\n",
        "!wget -O $model_download_path $seg_model_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bne4bNo5fAsx"
      },
      "source": [
        "Initialize a few environment variables [...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIIjeFdUe1EA"
      },
      "outputs": [],
      "source": [
        "os.environ[\"RESULTS_FOLDER\"] = \"/content/data/nnunet_output/\"\n",
        "os.environ[\"WEIGHTS_FOLDER\"] = \"/content/data/nnunet_output/nnUNet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wx8bWGVvew3P"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!nnUNet_install_pretrained_model_from_zip $model_download_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qu6eXpHx6iV"
      },
      "source": [
        "## **Parsing Cohort Information from BigQuery Tables**\n",
        "\n",
        "We can check the various fields of the table we populated by running the BigQuery query.\n",
        "\n",
        "This table will store one entry for each DICOM file in the dataset (therefore, expect thousands of rows!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "V27IJihCi9Kv",
        "outputId": "825fee32-f1c4-4264-c103-0ac42770c80d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of unique Patient IDs: 80\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18942 entries, 0 to 18941\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   PatientID          18942 non-null  object\n",
            " 1   collection_id      18942 non-null  object\n",
            " 2   source_DOI         18942 non-null  object\n",
            " 3   StudyInstanceUID   18942 non-null  object\n",
            " 4   SeriesInstanceUID  18942 non-null  object\n",
            " 5   SOPInstanceUID     18942 non-null  object\n",
            " 6   gcs_url            18942 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 1.0+ MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       PatientID collection_id                     source_DOI  \\\n",
              "0  PANCREAS_0001   pancreas_ct  10.7937/K9/TCIA.2016.tNB1kqBU   \n",
              "1  PANCREAS_0001   pancreas_ct  10.7937/K9/TCIA.2016.tNB1kqBU   \n",
              "2  PANCREAS_0001   pancreas_ct  10.7937/K9/TCIA.2016.tNB1kqBU   \n",
              "3  PANCREAS_0001   pancreas_ct  10.7937/K9/TCIA.2016.tNB1kqBU   \n",
              "4  PANCREAS_0001   pancreas_ct  10.7937/K9/TCIA.2016.tNB1kqBU   \n",
              "\n",
              "                                    StudyInstanceUID  \\\n",
              "0  1.2.826.0.1.3680043.2.1125.1.38381854871216336...   \n",
              "1  1.2.826.0.1.3680043.2.1125.1.38381854871216336...   \n",
              "2  1.2.826.0.1.3680043.2.1125.1.38381854871216336...   \n",
              "3  1.2.826.0.1.3680043.2.1125.1.38381854871216336...   \n",
              "4  1.2.826.0.1.3680043.2.1125.1.38381854871216336...   \n",
              "\n",
              "                                   SeriesInstanceUID  \\\n",
              "0  1.2.826.0.1.3680043.2.1125.1.68878959984837726...   \n",
              "1  1.2.826.0.1.3680043.2.1125.1.68878959984837726...   \n",
              "2  1.2.826.0.1.3680043.2.1125.1.68878959984837726...   \n",
              "3  1.2.826.0.1.3680043.2.1125.1.68878959984837726...   \n",
              "4  1.2.826.0.1.3680043.2.1125.1.68878959984837726...   \n",
              "\n",
              "                                      SOPInstanceUID  \\\n",
              "0  1.2.826.0.1.3680043.2.1125.1.12371411096899351...   \n",
              "1  1.2.826.0.1.3680043.2.1125.1.12376389450984884...   \n",
              "2  1.2.826.0.1.3680043.2.1125.1.13438245366954035...   \n",
              "3  1.2.826.0.1.3680043.2.1125.1.14285033913934517...   \n",
              "4  1.2.826.0.1.3680043.2.1125.1.15108061926999795...   \n",
              "\n",
              "                                             gcs_url  \n",
              "0  gs://public-datasets-idc/bb705d97-6ae7-4265-81...  \n",
              "1  gs://public-datasets-idc/65bd9a85-72ae-49b8-9c...  \n",
              "2  gs://public-datasets-idc/8dfc4047-afa7-4993-95...  \n",
              "3  gs://public-datasets-idc/e6fe842b-790d-4877-b3...  \n",
              "4  gs://public-datasets-idc/a84bafa7-5b62-4803-b6...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4819b257-bcce-409c-b5d1-ecc5e552d277\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PatientID</th>\n",
              "      <th>collection_id</th>\n",
              "      <th>source_DOI</th>\n",
              "      <th>StudyInstanceUID</th>\n",
              "      <th>SeriesInstanceUID</th>\n",
              "      <th>SOPInstanceUID</th>\n",
              "      <th>gcs_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PANCREAS_0001</td>\n",
              "      <td>pancreas_ct</td>\n",
              "      <td>10.7937/K9/TCIA.2016.tNB1kqBU</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.38381854871216336...</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.68878959984837726...</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.12371411096899351...</td>\n",
              "      <td>gs://public-datasets-idc/bb705d97-6ae7-4265-81...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PANCREAS_0001</td>\n",
              "      <td>pancreas_ct</td>\n",
              "      <td>10.7937/K9/TCIA.2016.tNB1kqBU</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.38381854871216336...</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.68878959984837726...</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.12376389450984884...</td>\n",
              "      <td>gs://public-datasets-idc/65bd9a85-72ae-49b8-9c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PANCREAS_0001</td>\n",
              "      <td>pancreas_ct</td>\n",
              "      <td>10.7937/K9/TCIA.2016.tNB1kqBU</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.38381854871216336...</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.68878959984837726...</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.13438245366954035...</td>\n",
              "      <td>gs://public-datasets-idc/8dfc4047-afa7-4993-95...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PANCREAS_0001</td>\n",
              "      <td>pancreas_ct</td>\n",
              "      <td>10.7937/K9/TCIA.2016.tNB1kqBU</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.38381854871216336...</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.68878959984837726...</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.14285033913934517...</td>\n",
              "      <td>gs://public-datasets-idc/e6fe842b-790d-4877-b3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PANCREAS_0001</td>\n",
              "      <td>pancreas_ct</td>\n",
              "      <td>10.7937/K9/TCIA.2016.tNB1kqBU</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.38381854871216336...</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.68878959984837726...</td>\n",
              "      <td>1.2.826.0.1.3680043.2.1125.1.15108061926999795...</td>\n",
              "      <td>gs://public-datasets-idc/a84bafa7-5b62-4803-b6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4819b257-bcce-409c-b5d1-ecc5e552d277')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4819b257-bcce-409c-b5d1-ecc5e552d277 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4819b257-bcce-409c-b5d1-ecc5e552d277');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "pat_id_list = sorted(list(set(cohort_df[\"PatientID\"].values)))\n",
        "\n",
        "print(\"Total number of unique Patient IDs:\", len(pat_id_list))\n",
        "\n",
        "display(cohort_df.info())\n",
        "\n",
        "display(cohort_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AolLtXOLVt7D"
      },
      "source": [
        "---\n",
        "\n",
        "## **Set Run Parameters**\n",
        "\n",
        "From this cell, we can configure the nnU-Net inference step - specifying, for instance, the type of model we want to run (among the four different models the framework provides), whether we want to use test time augmentation, or whether we want to export the soft probability maps of the segmentation masks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRmrt00589lv"
      },
      "outputs": [],
      "source": [
        "# FIXED PARAMETERS\n",
        "data_base_path = \"/content/data\"\n",
        "raw_base_path = \"/content/data/raw/tmp\"\n",
        "sorted_base_path = os.path.join(\"/content/data/raw/\", dataset_name, \"dicom\")\n",
        "\n",
        "processed_base_path = os.path.join(\"/content/data/processed/\", dataset_name)\n",
        "processed_nrrd_path = os.path.join(processed_base_path, \"nrrd\")\n",
        "processed_nifti_path = os.path.join(processed_base_path, \"nii\")\n",
        "\n",
        "processed_dicomseg_path = os.path.join(processed_base_path, \"dicomseg\")\n",
        "\n",
        "model_input_folder = \"/content/data/model_input/\"\n",
        "model_output_folder = \"/content/data/nnunet_output/\"\n",
        "\n",
        "dicomseg_json_path = \"/content/data/dicomseg_base_metadata.json\"\n",
        "\n",
        "# -----------------\n",
        "# nnU-Net pipeline parameters\n",
        "\n",
        "# choose from: \"2d\", \"3d_lowres\", \"3d_fullres\", \"3d_cascade_fullres\"\n",
        "nnunet_model = \"2d\"\n",
        "use_tta = False\n",
        "export_prob_maps = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **Functions We Can Push to a Module Later**\n",
        "\n",
        "After cloning the repo - \n",
        "\n",
        "The general utilities modules will be imported using the following syntax:\n",
        "\n",
        "```\n",
        "# make sure the __init__.py are properly set-up for this\n",
        "\n",
        "import aime.general_utils as aime_utils\n",
        "\n",
        "aime_utils.download_patient_data(...)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "The model-specific modules will be imported using the following syntax:\n",
        "\n",
        "```\n",
        "# make sure the __init__.py are properly set-up for this\n",
        "\n",
        "import aime.nnunet_pancreas as aime_model\n",
        "\n",
        "aime_model.process_patient(...)\n",
        "aime_model.pypla_postprocess(...)\n",
        "```"
      ],
      "metadata": {
        "id": "ACegIdodcCNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def numpy_to_nrrd(model_output_folder, processed_nrrd_path, pat_id,\n",
        "                  output_folder_name = \"pred_softmax\", output_dtype = \"uint8\",\n",
        "                  structure_list = [\"Background\", \"Pancreas\",\n",
        "                                    \"Pancreatic_cancer\"]):\n",
        "\n",
        "  \"\"\"\n",
        "  Convert softmax probability maps to NRRD. For simplicity, the probability maps\n",
        "  are converted by default to UInt8\n",
        "  Arguments:\n",
        "    model_output_folder : required - path to the folder where the inferred segmentation masks should be stored.\n",
        "    processed_nrrd_path : required - path to the folder where the preprocessed NRRD data are stored.\n",
        "    pat_id              : required - patient ID (used for naming purposes).\n",
        "    output_folder_name  : optional - name of the subfolder under the patient directory \n",
        "                                     (under `processed_nrrd_path`) where the softmax NRRD\n",
        "                                     files will be saved. Defaults to \"pred_softmax\".\n",
        "    output_dtype        : optional - output data type. Data type float16 is not supported by the NRRD standard,\n",
        "                                     so the choice should be between uint8, uint16 or float32. Please note this\n",
        "                                     will greatly impact the size of the DICOM PM file that will be generated.\n",
        "    structure_list      : optional - list of the structures whose probability maps are stored in the \n",
        "                                     first channel of the `.npz` file (output from the nnU-Net pipeline\n",
        "                                     when `export_prob_maps` is set to True). Defaults to the structure\n",
        "                                     list for the SegTHOR challenge (background = 0 included).\n",
        "  Outputs:\n",
        "    This function [...]\n",
        "  \"\"\"\n",
        "\n",
        "  pred_softmax_fn = pat_id + \".npz\"\n",
        "  pred_softmax_path = os.path.join(model_output_folder, pred_softmax_fn)\n",
        "\n",
        "  # parse NRRD file - we will make use of if to populate the header of the\n",
        "  # NRRD mask we are going to get from the inferred segmentation mask\n",
        "  ct_nrrd_path = os.path.join(processed_nrrd_path, pat_id, pat_id + \"_CT.nrrd\")\n",
        "  sitk_ct = sitk.ReadImage(ct_nrrd_path)\n",
        "\n",
        "  output_folder_path = os.path.join(processed_nrrd_path, pat_id, output_folder_name)\n",
        "  \n",
        "  if not os.path.exists(output_folder_path):\n",
        "    os.mkdir(output_folder_path)\n",
        "\n",
        "  pred_softmax_all = np.load(pred_softmax_path)[\"softmax\"]\n",
        "\n",
        "  # check if the model managed to segment the pancreatic cancer as well\n",
        "  # if not, exclude it from the list\n",
        "  has_cancer_seg = True if len(np.unique(pred_softmax_all)) > 2 else False\n",
        "\n",
        "  if has_cancer_seg == False:\n",
        "    structure_list = [\"Background\", \"Pancreas\"]\n",
        "\n",
        "  for channel, structure in enumerate(structure_list):\n",
        "\n",
        "    pred_softmax_segmask = pred_softmax_all[channel].astype(dtype = np.float32)\n",
        "\n",
        "    assert(output_dtype in [\"uint8\", \"uint16\", \"float32\"])      \n",
        "\n",
        "    if output_dtype == \"float32\":\n",
        "      # no rescale needed - the values will be between 0 and 1\n",
        "      # set SITK image dtype to Float32\n",
        "      sitk_dtype = sitk.sitkFloat32\n",
        "\n",
        "    elif output_dtype == \"uint8\":\n",
        "      # rescale between 0 and 255, quantize\n",
        "      pred_softmax_segmask = (255*pred_softmax_segmask).astype(np.int32)\n",
        "      # set SITK image dtype to UInt8\n",
        "      sitk_dtype = sitk.sitkUInt8\n",
        "\n",
        "    elif output_dtype == \"uint16\":\n",
        "      # rescale between 0 and 65536\n",
        "      pred_softmax_segmask = (65536*pred_softmax_segmask).astype(np.int32)\n",
        "      # set SITK image dtype to UInt16\n",
        "      sitk_dtype = sitk.sitkUInt16\n",
        "    \n",
        "    pred_softmax_segmask_sitk = sitk.GetImageFromArray(pred_softmax_segmask)\n",
        "    pred_softmax_segmask_sitk.CopyInformation(sitk_ct)\n",
        "    pred_softmax_segmask_sitk = sitk.Cast(pred_softmax_segmask_sitk, sitk_dtype)\n",
        "\n",
        "    output_fn = \"%s.nrrd\"%(structure)\n",
        "    output_path = os.path.join(output_folder_path, output_fn)\n",
        "\n",
        "    writer = sitk.ImageFileWriter()\n",
        "\n",
        "    writer.UseCompressionOn()\n",
        "    writer.SetFileName(output_path)\n",
        "    writer.Execute(pred_softmax_segmask_sitk)"
      ],
      "metadata": {
        "id": "VSy4fCB5cJVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pypla_nifti_to_nrrd(pred_nifti_path, processed_nrrd_path,\n",
        "                        pat_id, verbose = True):\n",
        "  \n",
        "  \"\"\"\n",
        "  NIfTI to NRRD file conversion using PyPlastimatch. \n",
        "  Arguments:\n",
        "    src_folder : required - path to the folder where the sorted data should be stored.\n",
        "    dst_folder : required - path to the folder where the preprocessed NRRD data are stored\n",
        "    pat_id     : required - patient ID (used for naming purposes).\n",
        "  \n",
        "  Returns:\n",
        "    pred_nrrd_path - \n",
        "  Outputs:\n",
        "    This function [...]\n",
        "  \"\"\"\n",
        "\n",
        "  pred_nrrd_path = os.path.join(processed_nrrd_path, pat_id, pat_id + \"_pred_pancreas.nrrd\")\n",
        "  log_file_path = os.path.join(processed_nrrd_path, pat_id, pat_id + \"_pypla.log\")\n",
        "  \n",
        "  # Inferred NIfTI segmask to NRRD\n",
        "  convert_args_pred = {\"input\" : pred_nifti_path, \n",
        "                       \"output-img\" : pred_nrrd_path}\n",
        "\n",
        "  pypla.convert(verbose = verbose,\n",
        "                path_to_log_file = log_file_path,\n",
        "                **convert_args_pred)\n",
        "  \n",
        "  return pred_nrrd_path"
      ],
      "metadata": {
        "id": "Fp_BIC-Hcd4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pypla_postprocess(processed_nrrd_path, model_output_folder, pat_id):\n",
        "\n",
        "  \"\"\"\n",
        "  Wrapper for NIfTI to NRRD file conversion using PyPlastimatch.\n",
        "  Arguments:\n",
        "    processed_nrrd_path  : required - path to the folder where the sorted data should be stored.\n",
        "    model_output_folder  : required - path to the folder where the inferred segmentation masks should be stored.\n",
        "    pat_id               : required - patient ID (used for naming purposes). \n",
        "  Outputs:\n",
        "    This function [...]\n",
        "  \"\"\"\n",
        "\n",
        "  pred_nifti_fn = pat_id + \".nii.gz\"\n",
        "  pred_nifti_path = os.path.join(model_output_folder, pred_nifti_fn)\n",
        "\n",
        "  pred_nrrd_path = pypla_nifti_to_nrrd(pred_nifti_path = pred_nifti_path,\n",
        "                                       processed_nrrd_path = processed_nrrd_path,\n",
        "                                       pat_id = pat_id, verbose = True)"
      ],
      "metadata": {
        "id": "bwWMcGn2cZaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n0qjPp1B_mv"
      },
      "source": [
        "## **Running the Analysis for a Single Patient**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import src.utils.gcs as gcs\n",
        "import src.utils.preprocessing as preprocessing\n",
        "import src.utils.processing as processing\n",
        "import src.utils.postprocessing as postprocessing"
      ],
      "metadata": {
        "id": "QFgxakXCF03g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell runs all the processing pipeline, from pre-processing to post-processing.\n",
        "\n",
        "For the sake of simplicity, all the extra code was organised in scripts that are fully documented and can be found at [this GitHub repository](https://github.com/ImagingDataCommons/ai_medima_misc/tree/main/nnunet/src)."
      ],
      "metadata": {
        "id": "0pFSCy5HoOp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess"
      ],
      "metadata": {
        "id": "AhnRGKyxucU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# maybe make some arguments kwargs and keep others the same?\n",
        "def process_patient_nnunet(model_input_folder, model_output_folder, nnunet_model,\n",
        "                           use_tta = False, export_prob_maps = False):\n",
        "\n",
        "  \"\"\"\n",
        "  Infer the thoracic organs at risk segmentation maps using one of the nnU-Net models.\n",
        "  Arguments:\n",
        "    model_input_folder  : required - path to the folder where the data to be inferred should be stored.\n",
        "    model_output_folder : required - path to the folder where the inferred segmentation masks will be stored.\n",
        "    nnunet_model        : required - pre-trained nnU-Net model to use during the inference phase.\n",
        "    use_tta             : optional - whether to use or not test time augmentation (TTA). Defaults to False.\n",
        "    export_prob_maps    : optional - whether to export or not softmax probabilities. Defaults to False.\n",
        "  Outputs:\n",
        "    This function [...]\n",
        "  \"\"\"\n",
        "  \n",
        "  assert(nnunet_model in [\"2d\", \"3d_lowres\", \"3d_fullres\", \"3d_cascade_fullres\"])\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  print(\"Running `nnUNet_predict` with `%s` model...\"%(nnunet_model))\n",
        "\n",
        "  pat_fn_list = sorted([f for f in os.listdir(model_input_folder) if \".nii.gz\" in f])\n",
        "  pat_fn_path = os.path.join(model_input_folder, pat_fn_list[-1])\n",
        "\n",
        "  print(\"Processing file at %s...\"%(pat_fn_path))\n",
        "\n",
        "  # run the inference phase\n",
        "  # note: this could also be done in a pythonic fashion by running\n",
        "  #       `nnUNet/nnunet/inference/predict.py` - but it would require\n",
        "  #       to set manually all the arguments that the user is not intended\n",
        "  #       to fiddle with; so stick with the bash executable\n",
        "\n",
        "  bash_command = list()\n",
        "  bash_command += [\"nnUNet_predict\"]\n",
        "  bash_command += [\"--input_folder\", \"%s\"%model_input_folder]\n",
        "  bash_command += [\"--output_folder\", \"%s\"%model_output_folder]\n",
        "  bash_command += [\"--task_name\", \"Task007_Pancreas\"]\n",
        "  bash_command += [\"--model\", \"%s\"%nnunet_model]\n",
        "  \n",
        "  if use_tta == False:\n",
        "    bash_command += [\"--disable_tta\"]\n",
        "  \n",
        "  if export_prob_maps == True:\n",
        "    bash_command += [\"--save_npz\"]\n",
        "\n",
        "  bash_return = subprocess.run(bash_command, check = True, text = True)\n",
        "\n",
        "  elapsed = time.time() - start_time\n",
        "\n",
        "  print(\"Done in %g seconds.\"%elapsed)"
      ],
      "metadata": {
        "id": "cYNw0WxctrPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpfMEkfvB8oZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "d51a0e23-e5be-43af-931f-1cebed14a41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing patient: PANCREAS_0001\n",
            "Copying files from IDC buckets to /content/data/raw/tmp/PANCREAS_0001...\n",
            "Done in 16.759 seconds.\n",
            "\n",
            "Sorting DICOM files...\n",
            "Done in 1.21641 seconds.\n",
            "Sorted DICOM data saved at: /content/data/raw/pancreas_ct/dicom/PANCREAS_0001\n",
            "Removing un-sorted data at /content/data/raw/tmp/PANCREAS_0001...\n",
            "... Done.\n",
            "\n",
            "Running 'plastimatch convert' with the specified arguments:\n",
            "  --input /content/data/raw/pancreas_ct/dicom/PANCREAS_0001/CT\n",
            "  --output-img /content/data/processed/pancreas_ct/nrrd/PANCREAS_0001/PANCREAS_0001_CT.nrrd\n",
            "... Done.\n",
            "\n",
            "Running 'plastimatch convert' with the specified arguments:\n",
            "  --input /content/data/raw/pancreas_ct/dicom/PANCREAS_0001/CT\n",
            "  --output-img /content/data/processed/pancreas_ct/nii/PANCREAS_0001/PANCREAS_0001_CT.nii.gz\n",
            "... Done.\n",
            "Copying /content/data/processed/pancreas_ct/nii/PANCREAS_0001/PANCREAS_0001_CT.nii.gz\n",
            "to /content/data/model_input/PANCREAS_0001_0000.nii.gz...\n",
            "... Done.\n",
            "Running `nnUNet_predict` with `2d` model...\n",
            "Processing file at /content/data/model_input/PANCREAS_0001_0000.nii.gz...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-96a618cdff2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m                        \u001b[0mmodel_output_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                        \u001b[0mnnunet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnunet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_tta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_tta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                        export_prob_maps = export_prob_maps)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m numpy_to_nrrd(model_output_folder = model_output_folder,\n",
            "\u001b[0;32m<ipython-input-26-b9f20332f2d9>\u001b[0m in \u001b[0;36mprocess_patient_nnunet\u001b[0;34m(model_input_folder, model_output_folder, nnunet_model, use_tta, export_prob_maps)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mbash_command\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"--save_npz\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0mbash_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbash_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    954\u001b[0m                 \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1609\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# sample patient - feel free to choose randomly!\n",
        "pat_id = \"PANCREAS_0001\"\n",
        "\n",
        "# -----------------\n",
        "# init\n",
        "\n",
        "print(\"Processing patient: %s\"%(pat_id))\n",
        "\n",
        "patient_df = cohort_df[cohort_df[\"PatientID\"] == pat_id]\n",
        "\n",
        "dicomseg_fn = pat_id + \"_SEG.dcm\"\n",
        "\n",
        "input_nifti_fn = pat_id + \"_0000.nii.gz\"\n",
        "input_nifti_path = os.path.join(model_input_folder, input_nifti_fn)\n",
        "\n",
        "pred_nifti_fn = pat_id + \".nii.gz\"\n",
        "pred_nifti_path = os.path.join(model_output_folder, pred_nifti_fn)\n",
        "\n",
        "pred_softmax_folder_name = \"pred_softmax\"\n",
        "pred_softmax_folder_path = os.path.join(processed_nrrd_path, pat_id, pred_softmax_folder_name)\n",
        "\n",
        "# -----------------\n",
        "# cross-load the CT data from the IDC buckets, run the preprocessing\n",
        "\n",
        "# data cross-loading\n",
        "gcs.download_patient_data(raw_base_path = raw_base_path,\n",
        "                          sorted_base_path = sorted_base_path,\n",
        "                          patient_df = patient_df,\n",
        "                          remove_raw = True)\n",
        "\n",
        "\n",
        "# DICOM CT to NRRD - good to have for a number of reasons\n",
        "preprocessing.pypla_dicom_ct_to_nrrd(sorted_base_path = sorted_base_path,\n",
        "                                     processed_nrrd_path = processed_nrrd_path,\n",
        "                                     pat_id = pat_id, verbose = True)\n",
        "\n",
        "# -----------------\n",
        "# DL-inference\n",
        "\n",
        "# DICOM CT to NIfTI - required for the processing\n",
        "preprocessing.pypla_dicom_ct_to_nifti(sorted_base_path = sorted_base_path,\n",
        "                                      processed_nifti_path = processed_nifti_path,\n",
        "                                      pat_id = pat_id, verbose = True)\n",
        "\n",
        "# prepare the `model_input` folder for the inference phase\n",
        "preprocessing.prep_input_data(processed_nifti_path = processed_nifti_path,\n",
        "                              model_input_folder = model_input_folder,\n",
        "                              pat_id = pat_id)\n",
        "\n",
        "# run the DL-based prediction\n",
        "process_patient_nnunet(model_input_folder = model_input_folder,\n",
        "                       model_output_folder = model_output_folder, \n",
        "                       nnunet_model = nnunet_model, use_tta = use_tta,\n",
        "                       export_prob_maps = export_prob_maps)\n",
        "\n",
        "numpy_to_nrrd(model_output_folder = model_output_folder,\n",
        "              processed_nrrd_path = processed_nrrd_path,\n",
        "              pat_id = pat_id,\n",
        "              output_folder_name = pred_softmax_folder_name)\n",
        "\n",
        "# remove the NIfTI file the prediction was computed from\n",
        "!rm $input_nifti_path\n",
        "\n",
        "postprocessing.pypla_postprocess(processed_nrrd_path = processed_nrrd_path,\n",
        "                                 model_output_folder = model_output_folder,\n",
        "                                 pat_id = pat_id)\n",
        "\n",
        "# FIXME: generate JSON for the new task\n",
        "# will do asap - prioritizing setting up the repository and code structure right now!\n",
        "\"\"\"\n",
        "postprocessing.nrrd_to_dicomseg(sorted_base_path = sorted_base_path,\n",
        "                                processed_base_path = processed_base_path,\n",
        "                                dicomseg_json_path = dicomseg_json_path,\n",
        "                                pat_id = pat_id)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "But1jZOmo1YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyplastimatch.utils import viz as viz_utils"
      ],
      "metadata": {
        "id": "SPAivMyyqReY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct_nii_path = os.path.join(\"/content/data/processed/pancreas_ct/nii/\", pat_id, pat_id + \"_CT.nii.gz\")\n",
        "seg_nii_path = os.path.join(\"/content/data/nnunet_output/\", pat_id + \".nii.gz\")\n",
        "softseg_nii_path = os.path.join(\"/content/data/nnunet_output/\", pat_id + \".npz\")\n",
        "\n",
        "\"\"\"\n",
        "alternative way of loading the resulting NIfTI files\n",
        "nibabel can sometimes take better care of the orientation of the\n",
        "converted/segmented images, but will orient the data differently by default\n",
        "\"\"\"\n",
        "\n",
        "#ct_nii = nib.load(ct_nii_path).dataobj\n",
        "#seg_nii = nib.load(seg_nii_path).dataobj\n",
        "\n",
        "ct_nii = sitk.GetArrayFromImage(sitk.ReadImage(ct_nii_path))\n",
        "seg_nii = sitk.GetArrayFromImage(sitk.ReadImage(seg_nii_path))"
      ],
      "metadata": {
        "id": "gxrHpkeapMKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some cases, the nnU-Net model will fail in segmenting the pancreatic cancer from the CT scan. The voxels of the NIfTI volume resulting from the pipeline will therefore take only two values: 0, for background, and 1, for pancreas.\n",
        "\n",
        "In the next cell, we can visualise the result using a simple widget - after taking care of the potential aforementioned exception."
      ],
      "metadata": {
        "id": "5Ydjya0OX5yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in some patients, no pancreatic cancer will be segmented\n",
        "has_cancer_seg = True if len(np.unique(seg_nii)) > 2 else False\n",
        "\n",
        "if has_cancer_seg:\n",
        "  # class #1\n",
        "  pancreas_nii = np.copy(seg_nii)\n",
        "  pancreas_nii[pancreas_nii > 1] = 0\n",
        "\n",
        "  # class #2\n",
        "  cancer_nii = np.copy(seg_nii)\n",
        "  cancer_nii[cancer_nii < 2] = 0\n",
        "  cancer_nii[cancer_nii == 2] = 1\n",
        "\n",
        "  _ = viz_utils.AxialSliceSegmaskViz(ct_volume = ct_nii,\n",
        "                                     segmask_dict = {\"pancreas\" : pancreas_nii,\n",
        "                                                     \"cancer\" : cancer_nii},\n",
        "                                     segmask_cmap_dict = {\"pancreas\" : my_greens,\n",
        "                                                          \"cancer\" : my_reds},\n",
        "                                     dpi = 100, figsize = (8, 8),\n",
        "                                     min_hu = -1024, max_hu = 1024)\n",
        "else:\n",
        "    _ = viz_utils.AxialSliceSegmaskViz(ct_volume = ct_nii, \n",
        "                                       segmask_dict = {\"pancreas\" : seg_nii},\n",
        "                                       segmask_cmap_dict = {\"pancreas\" : my_greens},\n",
        "                                       dpi = 100, figsize = (8, 8),\n",
        "                                       min_hu = -1024, max_hu = 1024)"
      ],
      "metadata": {
        "id": "imBup5S2qcpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **Data Download**"
      ],
      "metadata": {
        "id": "i2QqrdvXqQq0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ARmBD0lHdz_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rUrr7Kvmd0B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8pE0X9kid0D-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}